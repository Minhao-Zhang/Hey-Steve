{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up chroma db \n",
    "import chromadb\n",
    "# set up ollama\n",
    "import ollama\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma_client = chromadb.PersistentClient(path=\"chromadb/\")\n",
    "chroma_client = chromadb.Client()\n",
    "# chroma_client.delete_collection(\"my_collection\")\n",
    "collection = chroma_client.create_collection(name=\"my_collection\", get_or_create=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "def add_to_chroma_db(text: str):\n",
    "    global count \n",
    "    embed = ollama.embeddings(model='nomic-embed-text', prompt=text)\n",
    "    collection.add(embeddings=[embed[\"embedding\"]], documents=[text], ids=[f\"id{count}\"])\n",
    "    count += 1\n",
    "def query_chroma_db(text: str, n_results=20):\n",
    "    return collection.query(ollama.embeddings(model='nomic-embed-text', prompt=text)[\"embedding\"], n_results=n_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_content_with_parents(data):\n",
    "    \"\"\"\n",
    "    Recursively combines each line in _content with its parent keys.\n",
    "\n",
    "    Args:\n",
    "        data (dict): The JSON-like data with nested structure.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of strings where each string is a combined sentence.\n",
    "    \"\"\"\n",
    "    combined_sentences = []\n",
    "\n",
    "    def process_node(node, parents=[]):\n",
    "        if isinstance(node, dict):\n",
    "            for key, value in node.items():\n",
    "                if key == '_content' and isinstance(value, list):\n",
    "                    for line in value:\n",
    "                        combined_sentence = ' of '.join(parents) + ': ' + line.strip()\n",
    "                        combined_sentences.append(combined_sentence)\n",
    "                else:\n",
    "                    process_node(value, parents + [key])\n",
    "        elif isinstance(node, list):\n",
    "            for item in node:\n",
    "                process_node(item, parents)\n",
    "\n",
    "    process_node(data)\n",
    "    return combined_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all files in the json_data folder\n",
    "import os\n",
    "import json\n",
    "\n",
    "files = os.listdir(\"json_data\")\n",
    "for file in files:\n",
    "    with open(f\"json_data/{file}\") as f:\n",
    "        data = json.load(f)\n",
    "        combined_sentences = combine_content_with_parents(data)\n",
    "        for sentence in combined_sentences:\n",
    "            add_to_chroma_db(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_rag(question, model='llama3.1'):\n",
    "    responses = query_chroma_db(question, n_results=10)\n",
    "    # for response in responses['documents'][0]:\n",
    "    #     print(response)\n",
    "    context = \"\"\n",
    "    for i in range(len(responses['documents'][0])):\n",
    "        context += f\"{i+1}. {responses['documents'][0][i]} \"\n",
    "    \n",
    "    system = f\"\"\"\n",
    "    Use the following pieces of context to answer the question at the end. \n",
    "    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "    Use five sentences maximum and keep the answer as concise as possible. \n",
    "    {context}\n",
    "    \"\"\"\n",
    "        \n",
    "    response = ollama.chat(model=model, messages=[\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': system,\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': question,\n",
    "    },\n",
    "    ])\n",
    "    \n",
    "    return response['message']['content']\n",
    "\n",
    "def ask_question(question):\n",
    "    response = ollama.chat(model='llama3.1', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': question,\n",
    "    },\n",
    "    ])\n",
    "    \n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Where can I find wolves\n",
      "llama3.1: You can find wolves naturally spawning on grass blocks, dirt, coarse dirt, snow (in Bedrock Edition), snow blocks, or podzol in multiple biomes. The specific appearance and spawn rate may vary depending on the biome.\n",
      "================================================================================\n",
      "Question: Where can I find wolves\n",
      "QWen2: Wolves naturally spawn on various surfaces like grass blocks, dirt, coarse dirt, snow (in Bedrock Edition), snow blocks, or podzol. They have a 10% chance of spawning as babies and their appearance depends on the biome they are found in. Wolves can also be spawned using spawn eggs, monster spawners, commands, or due to bordering specific biomes like jungles or savannas.\n"
     ]
    }
   ],
   "source": [
    "question = \"Where can I find wolves\"\n",
    "\n",
    "llama_response = ask_rag(question)\n",
    "qwen2_response = ask_rag(question, model='qwen2')\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"llama3.1: {llama_response}\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"QWen2: {qwen2_response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
